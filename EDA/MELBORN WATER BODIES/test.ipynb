{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting requests\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting beautifulsoup4\n",
      "  Downloading beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests)\n",
      "  Downloading charset_normalizer-3.3.2-cp312-cp312-win_amd64.whl.metadata (34 kB)\n",
      "Collecting idna<4,>=2.5 (from requests)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests)\n",
      "  Downloading urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests)\n",
      "  Downloading certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4)\n",
      "  Downloading soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting numpy>=1.26.0 (from pandas)\n",
      "  Downloading numpy-2.1.2-cp312-cp312-win_amd64.whl.metadata (59 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\kakan\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kakan\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Downloading pandas-2.2.3-cp312-cp312-win_amd64.whl (11.5 MB)\n",
      "   ---------------------------------------- 0.0/11.5 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 1.6/11.5 MB 10.5 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 8.4/11.5 MB 23.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.5/11.5 MB 24.8 MB/s eta 0:00:00\n",
      "Downloading certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "Downloading charset_normalizer-3.3.2-cp312-cp312-win_amd64.whl (100 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading numpy-2.1.2-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   --------------------- ------------------ 6.8/12.6 MB 60.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.6/12.6 MB 39.4 MB/s eta 0:00:00\n",
      "Downloading pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "Downloading soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Downloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Installing collected packages: pytz, urllib3, tzdata, soupsieve, numpy, idna, charset-normalizer, certifi, requests, pandas, beautifulsoup4\n",
      "Successfully installed beautifulsoup4-4.12.3 certifi-2024.8.30 charset-normalizer-3.3.2 idna-3.10 numpy-2.1.2 pandas-2.2.3 pytz-2024.2 requests-2.32.3 soupsieve-2.6 tzdata-2024.2 urllib3-2.2.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "botocore 1.35.36 requires jmespath<2.0.0,>=0.7.1, which is not installed.\n",
      "yfinance 0.2.44 requires frozendict>=2.3.4, which is not installed.\n",
      "yfinance 0.2.44 requires lxml>=4.9.1, which is not installed.\n"
     ]
    }
   ],
   "source": [
    "pip install requests beautifulsoup4 pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Water storage levels saved to melbourne_water_storage_levels.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the Melbourne Water water storage levels page\n",
    "url = 'https://www.melbournewater.com.au/water-and-environment/water-management/water-storage-levels#/'\n",
    "\n",
    "# Send a GET request to fetch the HTML content\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # Adjust this section based on the actual structure\n",
    "    # For example, if the data is within specific divs or other elements\n",
    "    storage_levels = []\n",
    "    \n",
    "    # Check if there is a specific class or identifier for the data\n",
    "    containers = soup.find_all('div', class_='your-class-name')  # Adjust this\n",
    "    \n",
    "    for container in containers:\n",
    "        # Extract the data from the container\n",
    "        storage_data = {\n",
    "            'Storage Name': container.find('h3').get_text(strip=True),  # Adjust as needed\n",
    "            'Current Level': container.find('span', class_='current-level-class').get_text(strip=True),  # Adjust as needed\n",
    "            'Capacity': container.find('span', class_='capacity-class').get_text(strip=True),  # Adjust as needed\n",
    "            'Percentage': container.find('span', class_='percentage-class').get_text(strip=True)  # Adjust as needed\n",
    "        }\n",
    "        storage_levels.append(storage_data)\n",
    "\n",
    "    # Create a DataFrame and save it as a CSV file\n",
    "    df = pd.DataFrame(storage_levels)\n",
    "    df.to_csv('melbourne_water_storage_levels.csv', index=False)\n",
    "    \n",
    "    print(\"Water storage levels saved to melbourne_water_storage_levels.csv\")\n",
    "else:\n",
    "    print(\"Failed to retrieve the webpage.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
